{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-SPECIFIC: The folder paths holding simulation outputs and observations\n",
    "\n",
    "if not 'Simulation_output_folders' in locals():  \n",
    "    Simulation_output_folders = [\n",
    "        r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/output_5min_Bhima_1979_2016',\n",
    "        #r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/output_5min_Bhima_1979_2016',\n",
    "        #r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/Bhima_01011979_31122016_StdReservoirs2',\n",
    "        r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/Bhima_01011979_31122016',    \n",
    "    ]\n",
    "if not 'titles' in locals():\n",
    "    titles = ['dataset '+str(num+1) for num in range(len(Simulation_output_folders))]\n",
    "if not 'output_variable' in locals():\n",
    "    output_netcdf = 'discharge_daily'\n",
    "    output_variable = 'discharge'\n",
    "    \n",
    "# observations_folder holds one excel (observation_locations.xlsx) with names and locations, and\n",
    "    # a folder (Observations) with an Excel file for each station. The Excel files are named after the station names.\n",
    "    #\n",
    "    # observations_locations.xlsx has three columns: Station, Latitude, Longitude\n",
    "    #\n",
    "    # observations_folder\n",
    "    # ↵ observations_locations.xlsx\n",
    "    # ↵ Observations\n",
    "    #   ↵ StationName1.xlsx #first two rows not read\n",
    "    #   ↵ StationName2.xlsx #first two rows not read\n",
    "    #   ↵ ...\n",
    "if not 'template' in locals():\n",
    "     template = \"plotly_dark\"\n",
    "if not 'observations_folder' in locals():      \n",
    "    observations_folder = '/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Observations/River water level and discharge_Historical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset, num2date\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_discharge_folder = observations_folder + '/Observations'\n",
    "Simulated_output_paths = [folder + '/' + output_netcdf + '.nc' for folder in Simulation_output_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def geo_idx(dd, dd_array):\n",
    "   \"\"\"\n",
    "     search for nearest decimal degree in an array of decimal degrees and return the index.\n",
    "     np.argmin returns the indices of minium value along an axis.\n",
    "     so subtract dd from all values in dd_array, take absolute value and find index of minium.\n",
    "    \"\"\"\n",
    "   geo_idx = (np.abs(dd_array - dd)).argmin()\n",
    "   return geo_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "### Observed discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading observations\n"
     ]
    }
   ],
   "source": [
    "from functions import read_observations_excel\n",
    "\n",
    "Stations_namesLocations, DATES_observed, FLOWS_observed = read_observations_excel(observations_folder=observations_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "### Simulated discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading simulations\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m lat_idx \u001b[38;5;241m=\u001b[39m geo_idx(in_lat, lats)\n\u001b[1;32m     33\u001b[0m lon_idx \u001b[38;5;241m=\u001b[39m geo_idx(in_lon, lons)\n\u001b[0;32m---> 35\u001b[0m OUTPUTS_SIMULATED[sim]\u001b[38;5;241m.\u001b[39mappend(NC_SIMULATED[sim]\u001b[38;5;241m.\u001b[39mvariables[output_variable][:, lat_idx, lon_idx])\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5011\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__getitem__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5107\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable._toma\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5378\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable._check_safecast\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/netCDF4/utils.py:15\u001b[0m, in \u001b[0;36m_safecast\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# no bytes type in python < 2.6\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safecast\u001b[39m(a,b):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# check to see if array a can be safely cast\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# to array b.  A little less picky than numpy.can_cast.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         is_safe \u001b[38;5;241m=\u001b[39m ((a \u001b[38;5;241m==\u001b[39m b) \u001b[38;5;241m|\u001b[39m (np\u001b[38;5;241m.\u001b[39misnan(a) \u001b[38;5;241m&\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(b)))\u001b[38;5;241m.\u001b[39mall()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NC_SIMULATED = []\n",
    "LATS = []\n",
    "LONS = []\n",
    "DATES_SIMULATED = []\n",
    "OUTPUTS_SIMULATED = []\n",
    "\n",
    "print('Loading simulations')\n",
    "for simulation in Simulated_output_paths:\n",
    "    \n",
    "    nc_simulated = Dataset(simulation, 'r')\n",
    "    lats = nc_simulated.variables['lat'][:]\n",
    "    lons = nc_simulated.variables['lon'][:]\n",
    "    Dates_simulated = num2date(nc_simulated.variables['time'][:], units=nc_simulated.variables['time'].units)\n",
    "    for t in range(len(Dates_simulated)):\n",
    "        Dates_simulated[t] = np.datetime64(Dates_simulated[t])    \n",
    "    Outputs_simulated = []\n",
    "    \n",
    "    NC_SIMULATED.append(nc_simulated)\n",
    "    LATS.append(lats)\n",
    "    LONS.append(lons)\n",
    "    DATES_SIMULATED.append(Dates_simulated)\n",
    "    OUTPUTS_SIMULATED.append(Outputs_simulated)\n",
    "\n",
    "for discharge_location in Stations_namesLocations:\n",
    "    in_lat = discharge_location[1]\n",
    "    in_lon = discharge_location[2]\n",
    "    \n",
    "    for sim in range(len(Simulated_output_paths)):\n",
    "        lats = LATS[sim]\n",
    "        lons = LONS[sim]\n",
    "    \n",
    "        lat_idx = geo_idx(in_lat, lats)\n",
    "        lon_idx = geo_idx(in_lon, lons)\n",
    "\n",
    "        OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx, lon_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSD_allStn, NRMSD_allStn, KGE_allStn, bias_allStn, corr_allStn, NS_allStn = [],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import hydroStats as hydroStats\n",
    "for i in range(len(Stations_namesLocations)):\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(y=FLOWS_observed[i],\n",
    "                             x=DATES_observed[i],\n",
    "                    mode='lines+markers',\n",
    "                    name=titles[0],\n",
    "                            opacity=1, \n",
    "                             line=dict(width=1), #color='#1f77b4',\n",
    "                            marker = dict(size=2)))\n",
    "    \n",
    "    RMSD, NRMSD, KGE, bias, corr, NS = [],[],[],[],[],[]\n",
    "\n",
    "    for sim in range(len(Simulated_output_paths)):\n",
    "\n",
    "        fig.add_trace(go.Scatter(y=OUTPUTS_SIMULATED[sim][i],\n",
    "                                 x=DATES_SIMULATED[sim],\n",
    "                        mode='lines',\n",
    "                        name=titles[sim+1],\n",
    "                                line=dict(width=1))) #color='#ff7f0e', \n",
    "    #\"\"\"\n",
    "        FLOWS_simulated = OUTPUTS_SIMULATED[sim] \n",
    "        Dates_simulated = DATES_SIMULATED[sim]\n",
    "\n",
    "        max_simulated = max(FLOWS_simulated[i])\n",
    "\n",
    "        start = 0\n",
    "        for d in range(len(DATES_observed[i])):\n",
    "            # Find the match of the first observation to the first simulated day\n",
    "            if DATES_observed[i][d] == Dates_simulated[0]:\n",
    "                start = d\n",
    "                break\n",
    "        startSim = 0\n",
    "        if start == 0:\n",
    "            #Simulation begins before observations\n",
    "            #Find first simulation date\n",
    "            for d in range(len(Dates_simulated)):\n",
    "                if Dates_simulated[d] == DATES_observed[i][0]:\n",
    "                    startSim = d\n",
    "                    break\n",
    "\n",
    "        if startSim == 0 and start ==0 and Dates_simulated[0] != DATES_observed[i][-1]:\n",
    "            #print('There is no overlap of simulation and observation.')\n",
    "            KGE.append('-')\n",
    "            bias.append('-')\n",
    "            corr.append('-')\n",
    "            NS.append('-')\n",
    "            RMSD.append('-')\n",
    "            NRMSD.append('-')\n",
    "            \n",
    "        else:\n",
    "\n",
    "            oval=[]\n",
    "            o = FLOWS_observed[i][start:]\n",
    "            s = []\n",
    "\n",
    "            end = 0\n",
    "            for d in range(len(o)):\n",
    "                if not o[d]=='': #or 0?\n",
    "                    try:\n",
    "                        if FLOWS_simulated[i][d+startSim] > 0:\n",
    "                            s.append(FLOWS_simulated[i][d+startSim])\n",
    "                            oval.append(o[d])\n",
    "                    except: \n",
    "                        end = d\n",
    "                        break  \n",
    "                        \n",
    "            sval = np.asarray(s)\n",
    "            MSE = 0\n",
    "            for d in range(len(oval)):\n",
    "                MSE += (oval[d]-sval[d])**2\n",
    "            if len(oval) > 0:\n",
    "                rmsd = (MSE/len(oval)) ** .5\n",
    "            \n",
    "                RMSD.append(\"{:.2f}\".format(rmsd))\n",
    "                NRMSD.append(\"{:.2f}\".format(rmsd/np.mean(oval)))\n",
    "                KGE.append(\"{0:.2f}\".format(hydroStats.KGE(s=sval, o=oval, warmup=0)))\n",
    "                bias.append(\"{0:.2f}\".format(hydroStats.pc_bias2(s=sval, o=oval, warmup=0)))\n",
    "                corr.append(\"{0:.2f}\".format(hydroStats.correlation(s=sval, o=oval, warmup=0)))\n",
    "                NS.append(\"{0:.2f}\".format(hydroStats.NS(s=sval, o=oval, warmup=0)))\n",
    "            else:\n",
    "                RMSD.append('-')\n",
    "                NRMSD.append('-')\n",
    "                KGE.append('-')\n",
    "                bias.append('-')\n",
    "                corr.append('-')\n",
    "                NS.append('-')\n",
    "\n",
    "    data_WB = {'KGE': KGE, 'NS':NS, 'Bias':bias, 'Corr':corr, 'RMSD':RMSD, 'NRMSD':NRMSD}\n",
    "    df = pd.DataFrame(data_WB)\n",
    "    df=df.style.set_table_styles([{'selector': 'th', 'props': [('font-size', '12pt')]}]).set_properties(**{\"font-size\": \"12pt\"}).hide(axis='index') \n",
    "    \n",
    "    #\"\"\"\n",
    "    fig.update_layout(title=output_variable +': '+ Stations_namesLocations[i][0],\n",
    "                   yaxis_title=output_variable, template=template)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    print(Stations_namesLocations[i][0])\n",
    "    display(df)\n",
    "    \n",
    "    RMSD_allStn.append(RMSD) \n",
    "    NRMSD_allStn.append(NRMSD)\n",
    "    KGE_allStn.append(KGE)\n",
    "    bias_allStn.append(bias)\n",
    "    corr_allStn.append(corr)\n",
    "    NS_allStn.append(NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "titles = titles = ['v1 5min', 'v1 30sec', 'v2 30sec']\n",
    "z= [stn for stn in KGE_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Kling-Gupta efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=titles,\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()\n",
    "\n",
    "z= [stn for stn in KGE_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Kling-Gupta efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()\n",
    "\n",
    "§\n",
    "\n",
    "z= [stn for stn in NS_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Nash-Sutcliffe efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()\n",
    "\n",
    "z= [stn for stn in corr_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = 0, zmax = 1.0, title='Correlation',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "data=go.Surface(z=z),\n",
    "layout=go.Layout(\n",
    "    title=\"Mt Bruno Elevation\",\n",
    "    width=500,\n",
    "    height=500,\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
