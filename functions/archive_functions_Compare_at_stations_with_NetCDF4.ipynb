{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-SPECIFIC: The folder paths holding simulation outputs and observations\n",
    "\n",
    "if not 'Simulation_output_folders' in locals():  \n",
    "    Simulation_output_folders = [\n",
    "        r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/output_5min_Bhima_1979_2016',\n",
    "        #r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/output_5min_Bhima_1979_2016',\n",
    "        #r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/Bhima_01011979_31122016_StdReservoirs2',\n",
    "        #r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/Bhima_01011979_31122016',    \n",
    "    ]\n",
    "if not 'titles' in locals():\n",
    "    titles = ['observations']+['dataset '+str(num+1) for num in range(len(Simulation_output_folders))]\n",
    "else: \n",
    "    titles = ['observations'] + titles\n",
    "    \n",
    "if not 'output_variable' in locals():\n",
    "    output_netcdf = 'discharge_daily'\n",
    "    output_variable = 'discharge'\n",
    "    \n",
    "# observations_folder holds one excel (observation_locations.xlsx) with names and locations, and\n",
    "    # a folder (Observations) with an Excel file for each station. The Excel files are named after the station names.\n",
    "    #\n",
    "    # observations_locations.xlsx has three columns: Station, Latitude, Longitude\n",
    "    #\n",
    "    # observations_folder\n",
    "    # ↵ observations_locations.xlsx\n",
    "    # ↵ Observations\n",
    "    #   ↵ StationName1.xlsx #first two rows not read\n",
    "    #   ↵ StationName2.xlsx #first two rows not read\n",
    "    #   ↵ ...\n",
    "if not 'template' in locals():\n",
    "     template = \"plotly_dark\"\n",
    "if not 'observations_folder' in locals():      \n",
    "    observations_folder = '/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Observations/River water level and discharge_Historical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset, num2date\n",
    "import datetime\n",
    "#from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observed_discharge_folder = observations_folder + '/Observations' #inside functions\n",
    "Simulated_output_paths = [folder + '/' + output_netcdf + '.nc' for folder in Simulation_output_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def geo_idx(dd, dd_array):\n",
    "   \"\"\"\n",
    "     search for nearest decimal degree in an array of decimal degrees and return the index.\n",
    "     np.argmin returns the indices of minium value along an axis.\n",
    "     so subtract dd from all values in dd_array, take absolute value and find index of minium.\n",
    "    \"\"\"\n",
    "   geo_idx = (np.abs(dd_array - dd)).argmin()\n",
    "   return geo_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "### Observed discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading observations\n",
      "Loading observations\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/cwatm/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_observations_excel\n\u001b[0;32m----> 3\u001b[0m Stations_namesLocations, DATES_observed, FLOWS_observed \u001b[38;5;241m=\u001b[39m \u001b[43mread_observations_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservations_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/WAT-Tools/functions/functions.py:62\u001b[0m, in \u001b[0;36mread_observations_excel\u001b[0;34m(observations_folder)\u001b[0m\n\u001b[1;32m     55\u001b[0m sheet \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(observed_discharge_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m discharge_location[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# version 2 of observations: no headers, first two rows are not read. Dates in first column and observations in second.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#sheet = pd.read_excel(observed_discharge_folder + '/' + discharge_location[0] + '.xlsx', \u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#                         header=None, skiprows=2, \u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#                         names=['Date', 'Observation'])\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m sheet[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43msheet\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[1;32m     63\u001b[0m Dates_observed \u001b[38;5;241m=\u001b[39m sheet[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     64\u001b[0m Flows_observed \u001b[38;5;241m=\u001b[39m sheet[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObservation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cwatm/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cwatm/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "from functions import read_observations_excel\n",
    "\n",
    "Stations_namesLocations, DATES_observed, FLOWS_observed = read_observations_excel(observations_folder=observations_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "### Simulated discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "NC_SIMULATED = []\n",
    "LATS = []\n",
    "LONS = []\n",
    "DATES_SIMULATED = []\n",
    "OUTPUTS_SIMULATED = []\n",
    "\n",
    "print('Loading simulations')\n",
    "for simulation in Simulated_output_paths:\n",
    "    \n",
    "    nc_simulated = Dataset(simulation, 'r')\n",
    "    lats = nc_simulated.variables['lat'][:]\n",
    "    lons = nc_simulated.variables['lon'][:]\n",
    "    Dates_simulated = num2date(nc_simulated.variables['time'][:], units=nc_simulated.variables['time'].units, \n",
    "                               only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "    \n",
    "    Dates_simulated = pd.to_datetime(Dates_simulated).date\n",
    "\n",
    "    Outputs_simulated = []\n",
    "    \n",
    "    NC_SIMULATED.append(nc_simulated)\n",
    "    LATS.append(lats)\n",
    "    LONS.append(lons)\n",
    "    DATES_SIMULATED.append(Dates_simulated)\n",
    "    OUTPUTS_SIMULATED.append(Outputs_simulated)\n",
    "\n",
    "for discharge_location in Stations_namesLocations:\n",
    "    in_lat = discharge_location[1]\n",
    "    in_lon = discharge_location[2]\n",
    "    \n",
    "    for sim in range(len(Simulated_output_paths)):\n",
    "        lats = LATS[sim]\n",
    "        lons = LONS[sim]\n",
    "    \n",
    "        lat_idx = geo_idx(in_lat, lats)\n",
    "        lon_idx = geo_idx(in_lon, lons)\n",
    "\n",
    "        OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx, lon_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSD_allStn, NRMSD_allStn, KGE_allStn, bias_allStn, corr_allStn, NS_allStn = [],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import hydroStats as hydroStats\n",
    "import math\n",
    "for i in range(len(Stations_namesLocations)):\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(y=FLOWS_observed[i],\n",
    "                             x=DATES_observed[i],\n",
    "                    mode='lines+markers',\n",
    "                    name=titles[0],\n",
    "                            opacity=1, \n",
    "                             line=dict(width=1), #color='#1f77b4',\n",
    "                            marker = dict(size=2)))\n",
    "    \n",
    "    RMSD, NRMSD, KGE, bias, corr, NS = [],[],[],[],[],[]\n",
    "\n",
    "    for sim in range(len(Simulated_output_paths)):\n",
    "\n",
    "        fig.add_trace(go.Scatter(y=OUTPUTS_SIMULATED[sim][i],\n",
    "                                 x=DATES_SIMULATED[sim],\n",
    "                        mode='lines',\n",
    "                        name=titles[sim+1],\n",
    "                                line=dict(width=1))) #color='#ff7f0e', \n",
    "    #\"\"\"\n",
    "        FLOWS_simulated = OUTPUTS_SIMULATED[sim] \n",
    "        Dates_simulated = DATES_SIMULATED[sim]\n",
    "\n",
    "        max_simulated = max(FLOWS_simulated[i])\n",
    "\n",
    "        start = 0\n",
    "        for d in range(len(DATES_observed[i])):\n",
    "            # Find the match of the first observation to the first simulated day\n",
    "            #print(DATES_observed[i][d])\n",
    "            #print(Dates_simulated[0])\n",
    "            if DATES_observed[i][d] == Dates_simulated[0]:\n",
    "                start = d\n",
    "                break\n",
    "        startSim = 0\n",
    "        if start == 0:\n",
    "            #Simulation begins before observations\n",
    "            #Find first simulation date\n",
    "            for d in range(len(Dates_simulated)):\n",
    "                if Dates_simulated[d] == DATES_observed[i][0]:\n",
    "                    startSim = d\n",
    "                    break\n",
    "\n",
    "        if startSim == 0 and start ==0 and Dates_simulated[0] != DATES_observed[i][-1]:\n",
    "            #print('There is no overlap of simulation and observation.')\n",
    "            KGE.append('-')\n",
    "            bias.append('-')\n",
    "            corr.append('-')\n",
    "            NS.append('-')\n",
    "            RMSD.append('-')\n",
    "            NRMSD.append('-')\n",
    "            \n",
    "        else:\n",
    "            #print('d', d)\n",
    "\n",
    "            oval=[]\n",
    "            o = FLOWS_observed[i][start:]\n",
    "            s = []\n",
    "\n",
    "            end = 0\n",
    "            for d in range(len(o)):\n",
    "                if not o[d]=='' and not math.isnan(o[d]) : #or 0?\n",
    "                    try:\n",
    "                        if FLOWS_simulated[i][d+startSim] > 0:\n",
    "                            s.append(FLOWS_simulated[i][d+startSim])\n",
    "                            oval.append(o[d])\n",
    "                    except: \n",
    "                        end = d\n",
    "                        break  \n",
    "\n",
    "            sval = np.asarray(s)\n",
    "            MSE = 0\n",
    "            for d in range(len(oval)):\n",
    "                MSE += (oval[d]-sval[d])**2\n",
    "            if len(oval) > 0:\n",
    "                rmsd = (MSE/len(oval)) ** .5\n",
    "            \n",
    "                RMSD.append(\"{:.2f}\".format(rmsd))\n",
    "                NRMSD.append(\"{:.2f}\".format(rmsd/np.mean(oval)))\n",
    "                KGE.append(\"{0:.2f}\".format(hydroStats.KGE(s=sval, o=oval, warmup=0)))\n",
    "                bias.append(\"{0:.2f}\".format(hydroStats.pc_bias2(s=sval, o=oval, warmup=0)))\n",
    "                corr.append(\"{0:.2f}\".format(hydroStats.correlation(s=sval, o=oval, warmup=0)))\n",
    "                NS.append(\"{0:.2f}\".format(hydroStats.NS(s=sval, o=oval, warmup=0)))\n",
    "            else:\n",
    "                RMSD.append('-')\n",
    "                NRMSD.append('-')\n",
    "                KGE.append('-')\n",
    "                bias.append('-')\n",
    "                corr.append('-')\n",
    "                NS.append('-')\n",
    "\n",
    "    data_WB = {'KGE': KGE, 'NS':NS, 'Bias':bias, 'Corr':corr, 'RMSD':RMSD, 'NRMSD':NRMSD}\n",
    "    df = pd.DataFrame(data_WB)\n",
    "    df=df.style.set_table_styles([{'selector': 'th', 'props': [('font-size', '12pt')]}]).set_properties(**{\"font-size\": \"12pt\"}).hide(axis='index') \n",
    "    \n",
    "    #\"\"\"\n",
    "    fig.update_layout(title=output_variable +': '+ Stations_namesLocations[i][0],\n",
    "                   yaxis_title=output_variable, template=template)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    print(Stations_namesLocations[i][0])\n",
    "    display(df)\n",
    "    \n",
    "    RMSD_allStn.append(RMSD) \n",
    "    NRMSD_allStn.append(NRMSD)\n",
    "    KGE_allStn.append(KGE)\n",
    "    bias_allStn.append(bias)\n",
    "    corr_allStn.append(corr)\n",
    "    NS_allStn.append(NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "z= [stn for stn in KGE_allStn]\n",
    "titles = titles[1:]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Kling-Gupta efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=titles,\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "#fig.show()\n",
    "\n",
    "z= [stn for stn in KGE_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Kling-Gupta efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()\n",
    "\n",
    "\n",
    "z= [stn for stn in NS_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Nash-Sutcliffe efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()\n",
    "\n",
    "z= [stn for stn in corr_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = 0, zmax = 1.0, title='Correlation',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = go.Figure(\n",
    "data=go.Surface(z=z),\n",
    "layout=go.Layout(\n",
    "    title=\"Mt Bruno Elevation\",\n",
    "    width=500,\n",
    "    height=500,\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
