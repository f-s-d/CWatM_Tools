{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER-SPECIFIC: The folder paths holding simulation outputs and observations\n",
    "\n",
    "if not 'Simulation_output_folders' in locals():  \n",
    "    Simulation_output_folders = [\n",
    "        r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/output_5min_Bhima_1979_2016',\n",
    "        #r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/output_5min_Bhima_1979_2016',\n",
    "        #r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/Bhima_01011979_31122016_StdReservoirs2',\n",
    "        r'/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Results/Bhima_01011979_31122016',    \n",
    "    ]\n",
    "if not 'titles' in locals():\n",
    "    titles = ['dataset '+str(num+1) for num in range(len(Simulation_output_folders))]\n",
    "if not 'output_variable' in locals():\n",
    "    output_netcdf = 'discharge_daily'\n",
    "    output_variable = 'discharge'\n",
    "    \n",
    "# observations_folder holds one excel (observation_locations.xlsx) with names and locations, and\n",
    "    # a folder (Observations) with an Excel file for each station. The Excel files are named after the station names.\n",
    "    #\n",
    "    # observations_locations.xlsx has three columns: Station, Latitude, Longitude\n",
    "    #\n",
    "    # observations_folder\n",
    "    # ↵ observations_locations.xlsx\n",
    "    # ↵ Observations\n",
    "    #   ↵ StationName1.xlsx #first two rows not read\n",
    "    #   ↵ StationName2.xlsx #first two rows not read\n",
    "    #   ↵ ...\n",
    "if not 'template' in locals():\n",
    "     template = \"plotly_dark\"\n",
    "if not 'observations_folder' in locals():      \n",
    "    observations_folder = '/Users/admin/Desktop/OneDrive - IIASA/Papers/2024_Refining_humans_CWatM/Observations/River water level and discharge_Historical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset, num2date\n",
    "import datetime\n",
    "#from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observed_discharge_folder = observations_folder + '/Observations' #inside functions\n",
    "Simulated_output_paths = [folder + '/' + output_netcdf + '.nc' for folder in Simulation_output_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def geo_idx(dd, dd_array):\n",
    "   \"\"\"\n",
    "     search for nearest decimal degree in an array of decimal degrees and return the index.\n",
    "     np.argmin returns the indices of minium value along an axis.\n",
    "     so subtract dd from all values in dd_array, take absolute value and find index of minium.\n",
    "    \"\"\"\n",
    "   geo_idx = (np.abs(dd_array - dd)).argmin()\n",
    "   return geo_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "### Observed discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading observations\n"
     ]
    },
    {
     "ename": "XLRDError",
     "evalue": "Excel xlsx file; not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_observations_excel\n\u001b[0;32m----> 3\u001b[0m Stations_namesLocations, DATES_observed, FLOWS_observed \u001b[38;5;241m=\u001b[39m \u001b[43mread_observations_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservations_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/CWatM_Tools/functions/functions.py:57\u001b[0m, in \u001b[0;36mread_observations_excel\u001b[0;34m(observations_folder)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m discharge_location \u001b[38;5;129;01min\u001b[39;00m Observations_namesLocations_array:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m discharge_location[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m observed_folder_list:\n\u001b[0;32m---> 57\u001b[0m         book \u001b[38;5;241m=\u001b[39m \u001b[43mxlrd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobserved_discharge_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdischarge_location\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m         sheet \u001b[38;5;241m=\u001b[39m book\u001b[38;5;241m.\u001b[39msheet_by_index(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     59\u001b[0m         num_rows \u001b[38;5;241m=\u001b[39m sheet\u001b[38;5;241m.\u001b[39mnrows\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cwatm/lib/python3.12/site-packages/xlrd/__init__.py:170\u001b[0m, in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# We have to let unknown file formats pass through here, as some ancient\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# files that xlrd can parse don't start with the expected signature.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_format \u001b[38;5;129;01mand\u001b[39;00m file_format \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XLRDError(FILE_FORMAT_DESCRIPTIONS[file_format]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; not supported\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    172\u001b[0m bk \u001b[38;5;241m=\u001b[39m open_workbook_xls(\n\u001b[1;32m    173\u001b[0m     filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m    174\u001b[0m     logfile\u001b[38;5;241m=\u001b[39mlogfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m     ignore_workbook_corruption\u001b[38;5;241m=\u001b[39mignore_workbook_corruption,\n\u001b[1;32m    183\u001b[0m )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bk\n",
      "\u001b[0;31mXLRDError\u001b[0m: Excel xlsx file; not supported"
     ]
    }
   ],
   "source": [
    "from functions import read_observations_excel\n",
    "\n",
    "Stations_namesLocations, DATES_observed, FLOWS_observed = read_observations_excel(observations_folder=observations_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "### Simulated discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "NC_SIMULATED = []\n",
    "LATS = []\n",
    "LONS = []\n",
    "DATES_SIMULATED = []\n",
    "OUTPUTS_SIMULATED = []\n",
    "\n",
    "print('Loading simulations')\n",
    "for simulation in Simulated_output_paths:\n",
    "    \n",
    "    nc_simulated = Dataset(simulation, 'r')\n",
    "    lats = nc_simulated.variables['lat'][:]\n",
    "    lons = nc_simulated.variables['lon'][:]\n",
    "    Dates_simulated = num2date(nc_simulated.variables['time'][:], units=nc_simulated.variables['time'].units, \n",
    "                               only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "    \n",
    "    Dates_simulated = pd.to_datetime(Dates_simulated).date\n",
    "\n",
    "    Outputs_simulated = []\n",
    "    \n",
    "    NC_SIMULATED.append(nc_simulated)\n",
    "    LATS.append(lats)\n",
    "    LONS.append(lons)\n",
    "    DATES_SIMULATED.append(Dates_simulated)\n",
    "    OUTPUTS_SIMULATED.append(Outputs_simulated)\n",
    "\n",
    "for discharge_location in Stations_namesLocations:\n",
    "    in_lat = discharge_location[1]\n",
    "    in_lon = discharge_location[2]\n",
    "    \n",
    "    for sim in range(len(Simulated_output_paths)):\n",
    "        lats = LATS[sim]\n",
    "        lons = LONS[sim]\n",
    "    \n",
    "        lat_idx = geo_idx(in_lat, lats)\n",
    "        lon_idx = geo_idx(in_lon, lons)\n",
    "\n",
    "        OUTPUTS_SIMULATED[sim].append(NC_SIMULATED[sim].variables[output_variable][:, lat_idx, lon_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSD_allStn, NRMSD_allStn, KGE_allStn, bias_allStn, corr_allStn, NS_allStn = [],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import hydroStats as hydroStats\n",
    "import math\n",
    "for i in range(len(Stations_namesLocations)):\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(y=FLOWS_observed[i],\n",
    "                             x=DATES_observed[i],\n",
    "                    mode='lines+markers',\n",
    "                    name=titles[0],\n",
    "                            opacity=1, \n",
    "                             line=dict(width=1), #color='#1f77b4',\n",
    "                            marker = dict(size=2)))\n",
    "    \n",
    "    RMSD, NRMSD, KGE, bias, corr, NS = [],[],[],[],[],[]\n",
    "\n",
    "    for sim in range(len(Simulated_output_paths)):\n",
    "\n",
    "        fig.add_trace(go.Scatter(y=OUTPUTS_SIMULATED[sim][i],\n",
    "                                 x=DATES_SIMULATED[sim],\n",
    "                        mode='lines',\n",
    "                        name=titles[sim+1],\n",
    "                                line=dict(width=1))) #color='#ff7f0e', \n",
    "    #\"\"\"\n",
    "        FLOWS_simulated = OUTPUTS_SIMULATED[sim] \n",
    "        Dates_simulated = DATES_SIMULATED[sim]\n",
    "\n",
    "        max_simulated = max(FLOWS_simulated[i])\n",
    "\n",
    "        start = 0\n",
    "        for d in range(len(DATES_observed[i])):\n",
    "            # Find the match of the first observation to the first simulated day\n",
    "            #print(DATES_observed[i][d])\n",
    "            #print(Dates_simulated[0])\n",
    "            if DATES_observed[i][d] == Dates_simulated[0]:\n",
    "                start = d\n",
    "                break\n",
    "        startSim = 0\n",
    "        if start == 0:\n",
    "            #Simulation begins before observations\n",
    "            #Find first simulation date\n",
    "            for d in range(len(Dates_simulated)):\n",
    "                if Dates_simulated[d] == DATES_observed[i][0]:\n",
    "                    startSim = d\n",
    "                    break\n",
    "\n",
    "        if startSim == 0 and start ==0 and Dates_simulated[0] != DATES_observed[i][-1]:\n",
    "            #print('There is no overlap of simulation and observation.')\n",
    "            KGE.append('-')\n",
    "            bias.append('-')\n",
    "            corr.append('-')\n",
    "            NS.append('-')\n",
    "            RMSD.append('-')\n",
    "            NRMSD.append('-')\n",
    "            \n",
    "        else:\n",
    "            #print('d', d)\n",
    "\n",
    "            oval=[]\n",
    "            o = FLOWS_observed[i][start:]\n",
    "            s = []\n",
    "\n",
    "            end = 0\n",
    "            for d in range(len(o)):\n",
    "                if not o[d]=='' and not math.isnan(o[d]) : #or 0?\n",
    "                    try:\n",
    "                        if FLOWS_simulated[i][d+startSim] > 0:\n",
    "                            s.append(FLOWS_simulated[i][d+startSim])\n",
    "                            oval.append(o[d])\n",
    "                    except: \n",
    "                        end = d\n",
    "                        break  \n",
    "\n",
    "            sval = np.asarray(s)\n",
    "            MSE = 0\n",
    "            for d in range(len(oval)):\n",
    "                MSE += (oval[d]-sval[d])**2\n",
    "            if len(oval) > 0:\n",
    "                rmsd = (MSE/len(oval)) ** .5\n",
    "            \n",
    "                RMSD.append(\"{:.2f}\".format(rmsd))\n",
    "                NRMSD.append(\"{:.2f}\".format(rmsd/np.mean(oval)))\n",
    "                KGE.append(\"{0:.2f}\".format(hydroStats.KGE(s=sval, o=oval, warmup=0)))\n",
    "                bias.append(\"{0:.2f}\".format(hydroStats.pc_bias2(s=sval, o=oval, warmup=0)))\n",
    "                corr.append(\"{0:.2f}\".format(hydroStats.correlation(s=sval, o=oval, warmup=0)))\n",
    "                NS.append(\"{0:.2f}\".format(hydroStats.NS(s=sval, o=oval, warmup=0)))\n",
    "            else:\n",
    "                RMSD.append('-')\n",
    "                NRMSD.append('-')\n",
    "                KGE.append('-')\n",
    "                bias.append('-')\n",
    "                corr.append('-')\n",
    "                NS.append('-')\n",
    "\n",
    "    data_WB = {'KGE': KGE, 'NS':NS, 'Bias':bias, 'Corr':corr, 'RMSD':RMSD, 'NRMSD':NRMSD}\n",
    "    df = pd.DataFrame(data_WB)\n",
    "    df=df.style.set_table_styles([{'selector': 'th', 'props': [('font-size', '12pt')]}]).set_properties(**{\"font-size\": \"12pt\"}).hide(axis='index') \n",
    "    \n",
    "    #\"\"\"\n",
    "    fig.update_layout(title=output_variable +': '+ Stations_namesLocations[i][0],\n",
    "                   yaxis_title=output_variable, template=template)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    print(Stations_namesLocations[i][0])\n",
    "    display(df)\n",
    "    \n",
    "    RMSD_allStn.append(RMSD) \n",
    "    NRMSD_allStn.append(NRMSD)\n",
    "    KGE_allStn.append(KGE)\n",
    "    bias_allStn.append(bias)\n",
    "    corr_allStn.append(corr)\n",
    "    NS_allStn.append(NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "z= [stn for stn in KGE_allStn]\n",
    "titles = titles[1:]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Kling-Gupta efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=titles,\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()\n",
    "\n",
    "z= [stn for stn in KGE_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Kling-Gupta efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()\n",
    "\n",
    "\n",
    "z= [stn for stn in NS_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = -2, zmax = 1.0, title='Nash-Sutcliffe efficiency',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()\n",
    "\n",
    "z= [stn for stn in corr_allStn]\n",
    "fig = px.imshow(z, template=template, text_auto=True, zmin = 0, zmax = 1.0, title='Correlation',\n",
    "                labels=dict(y=\"Station\", x='Run', color=\"Rating\"),\n",
    "                x=[i for i in range(len(Simulation_output_folders))],\n",
    "                y=[i[0] for i in Stations_namesLocations])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = go.Figure(\n",
    "data=go.Surface(z=z),\n",
    "layout=go.Layout(\n",
    "    title=\"Mt Bruno Elevation\",\n",
    "    width=500,\n",
    "    height=500,\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
